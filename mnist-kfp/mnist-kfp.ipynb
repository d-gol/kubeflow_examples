{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6331ZSsQGY3"
   },
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enZ300Bflq80"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import kfp\n",
    "from kfp.components import func_to_container_op, InputPath, OutputPath\n",
    "from kfp import dsl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import kfp\n",
    "from kfp.components import func_to_container_op, InputPath, OutputPath\n",
    "from typing import NamedTuple\n",
    "from kfp import dsl\n",
    "\n",
    "@func_to_container_op\n",
    "def read_data(output_text_path: OutputPath(str)):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from zipfile import ZipFile\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "    x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "    np.save('xtrain.npy', x_train)\n",
    "    np.save('ytrain.npy', y_train)\n",
    "\n",
    "    np.save('xtest.npy', x_test)\n",
    "    np.save('ytest.npy', y_test)\n",
    "    \n",
    "    zipObj = ZipFile(output_text_path, 'w')\n",
    "    \n",
    "    zipObj.write('xtrain.npy')\n",
    "    zipObj.write('ytrain.npy')\n",
    "    zipObj.write('xtest.npy')\n",
    "    zipObj.write('ytest.npy')\n",
    "    \n",
    "    zipObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "@func_to_container_op\n",
    "def preprocess_data(text_path: InputPath(), output_text_path: OutputPath()):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import tarfile\n",
    "    print('tarfile imported')\n",
    "    from zipfile import ZipFile\n",
    "    \n",
    "    with ZipFile(text_path, 'r') as zipObj:\n",
    "       zipObj.extractall()\n",
    "    \n",
    "    # Load data\n",
    "    x_train = np.load('xtrain.npy')\n",
    "    y_train = np.load('ytrain.npy')\n",
    "\n",
    "    x_test = np.load('xtest.npy')\n",
    "    y_test = np.load('ytest.npy')\n",
    "    \n",
    "    # Filter 3 and 6\n",
    "    def filter_36(x, y):\n",
    "        keep = (y == 3) | (y == 6)\n",
    "        x, y = x[keep], y[keep]\n",
    "        y = y == 3\n",
    "        return x,y\n",
    "    \n",
    "    print(\"Number of unfiltered training examples:\", len(x_train))\n",
    "    print(\"Number of unfiltered test examples:\", len(x_test))\n",
    "    \n",
    "    x_train, y_train = filter_36(x_train, y_train)\n",
    "    x_test, y_test = filter_36(x_test, y_test)\n",
    "\n",
    "    print(\"Number of filtered training examples:\", len(x_train))\n",
    "    print(\"Number of filtered test examples:\", len(x_test))\n",
    "    \n",
    "    # Save modified data\n",
    "    np.save('xtrain_filtered.npy', x_train)\n",
    "    np.save('ytrain_filtered.npy', y_train)\n",
    "\n",
    "    np.save('xtest_filtered.npy', x_test)\n",
    "    np.save('ytest_filtered.npy', y_test)\n",
    "    \n",
    "    zipObj = ZipFile(output_text_path, 'w')\n",
    "    \n",
    "    zipObj.write('xtrain_filtered.npy')\n",
    "    zipObj.write('ytrain_filtered.npy')\n",
    "    zipObj.write('xtest_filtered.npy')\n",
    "    zipObj.write('ytest_filtered.npy')\n",
    "    \n",
    "    zipObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "@func_to_container_op\n",
    "def model_full(text_path: InputPath(), output_text_path: OutputPath()):\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    import tensorflow as tf\n",
    "    from zipfile import ZipFile\n",
    "    import numpy as np\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    with ZipFile(text_path, 'r') as zipObj:\n",
    "       zipObj.extractall()\n",
    "    \n",
    "    # Load data\n",
    "    x_train = np.load('xtrain_filtered.npy')\n",
    "    y_train = np.load('ytrain_filtered.npy')\n",
    "\n",
    "    x_test = np.load('xtest_filtered.npy')\n",
    "    y_test = np.load('ytest_filtered.npy')\n",
    "    \n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "    cnn_results = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    with open(output_text_path, 'w') as writer:\n",
    "        writer.write(str(cnn_results) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "@func_to_container_op\n",
    "def model_fair(text_path: InputPath(), output_text_path: OutputPath()):\n",
    "    import tensorflow as tf\n",
    "    from zipfile import ZipFile\n",
    "    import numpy as np\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28,28,1)))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    with ZipFile(text_path, 'r') as zipObj:\n",
    "       zipObj.extractall()\n",
    "    \n",
    "    # Load data\n",
    "    x_train = np.load('xtrain_filtered.npy')\n",
    "    y_train = np.load('ytrain_filtered.npy')\n",
    "\n",
    "    x_test = np.load('xtest_filtered.npy')\n",
    "    y_test = np.load('ytest_filtered.npy')\n",
    "    \n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "    cnn_results = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    with open(output_text_path, 'w') as writer:\n",
    "        writer.write(str(cnn_results) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_to_container_op\n",
    "def models_evaluate(text_path_0: InputPath(), text_path_1: InputPath()):\n",
    "    print('model 0:')\n",
    "    with open(text_path_0, 'r') as reader:\n",
    "        for line in reader:\n",
    "            print(line, end = '')\n",
    "    print('model 1:')\n",
    "    with open(text_path_1, 'r') as reader:\n",
    "        for line in reader:\n",
    "            print(line, end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='ML first',\n",
    "    description='ML first).'\n",
    ")\n",
    "def ml_pipeline_first():\n",
    "    data_dir = read_data()\n",
    "    new_dir = preprocess_data(data_dir.output)\n",
    "    cnn_res = model_full(new_dir.output)\n",
    "    fairnn_res = model_fair(new_dir.output)\n",
    "    models_evaluate(cnn_res.output, fairnn_res.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(ml_pipeline_first, 'ml_pipeline_demo.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mnist.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "gitlab-registry.cern.ch/ai-ml/kubeflow_images/tensorflow-notebook-gpu-2.1.0:v0.6.1-30",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
